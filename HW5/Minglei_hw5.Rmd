#Problem 1
```{r}
library(rstudioapi)
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
fish<-read.csv('FishMercury.csv')
head(fish)
```
#(a)
```{r}
boxplot(fish)
```
Comment: There is an outlier far away from the main part, which make the plot to be kind of weird.

#(b)
```{r}
n=100
N=10000
rec_mean=numeric(N)
for (i in 1:N){
  boot=sample(fish$Mercury, n, replace=TRUE)
  rec_mean[i]=mean(boot)
}
mean(rec_mean)
sd(rec_mean)
quantile(rec_mean,c(0.025,0.975))
```
#(c)
```{r}
cleaned_fish=fish$Mercury[2:30]
rec_mean_new=numeric(N)
for (i in 1:N){
  boot=sample(cleaned_fish, n, replace=TRUE)
  rec_mean_new[i]=mean(boot)
}
mean(rec_mean_new)
sd(rec_mean_new)
quantile(rec_mean_new,c(0.025,0.975))
```

Comment: The sd becomes smaller and the confidence interval becomes shorter. So it might be better for us to first remove the meaningless outliers before bootstraping.

#(d)
```{r}
hist(rec_mean)
hist(rec_mean_new)
```
Comment: After removing the outlier, the distribution becomes more balanced and more symmetric, and the sd becomes smaller.

#Problem 2
```{r}
cereals<-read.csv('Cereals.csv')
head(cereals)
```
#(a)
```{r}
table_new=with(cereals,table(Shelf,Age))
table_new
```
#(b)
```{r}
chisq.test(table_new)
```
Comment: The age of customers and the shelves they reach to are somehow related.

#(c)
```{r}
table_expected=table_new
for (i in 1:3){
  for (j in 1:2){
    table_expected[i,j]=sum(table_new[i,1:2])*sum(table_new[1:3,j],axis=1)/43
  }
}
table_expected
```
Comment: Some expected values are so small that the normal approximation can fail.

#Problem 3
```{r}
A=rnorm(20)
B=rnorm(30,1,2)
df=data.frame(class=c(rep('A',20),rep('B',30)), data=c(A,B))

mytest=function(mydf){
  agg=aggregate(data~class,data=mydf,FUN=mean)
  return(agg$data[1]-agg$data[2])
}

permute=function(){
  df_permute=df
  df_permute$class=df_permute$class[sample(50,50,replace=F)]
  return(mytest(df_permute))
}

N=10000
test=replicate(N,permute())

hist(test,main='Null Distribution',prob=T)
abline(v=mytest(df),col=2,lwd=2)
mean(test<mytest(df))
```
Comment: We cannot reject the null hypothesis. We cannot assert that the mean of B is larger than A.

#Problem 4
```{r}
birth<-read.csv('NCBirths2004.csv')
head(birth)
```
```{r}
library(ggplot2)
birth=birth[c('Weight','Smoker')]
ggplot(birth, aes(x=Smoker,y=Weight,fill=Smoker))+
  geom_boxplot()
```
We create the null hypothesis that there's no difference between weights of babies with mothers being smokers or not. The alternative hypothesis is babies born to mothers who smoke weigh less on average than babies born to non-smoking mothers.
```{r}
smoker=subset(birth,select=Weight,subset=Smoker=='Yes',drop=T)
nonsmoker=subset(birth,select=Weight,subset=Smoker=='No',drop=T)
t.test(smoker,nonsmoker,alt='less')
```
At the significance level of 0.05, we can reject the null hypothesis. And yes, we can draw the conclusion that babies born to mothers who smoke weigh less on average than babies born to non-smoking mothers.


#Problem 5
```{r}
interval<-function(mean,std,n,percent){
  alpha=1-percent
  start=mean-std/sqrt(n)*qt(1-alpha/2,df=n-1)
  end=mean+std/sqrt(n)*qt(1-alpha/2,df=n-1)
  return (c(start,end))
}

interval(18.05,5,20,0.9)
```
#Problem 6
```{r}
girls<-read.csv('Girls2004.csv')
head(girls)
```
#(a)
```{r}
girls=girls[c('Weight','Smoker')]
ggplot(girls, aes(x=Smoker,y=Weight,fill=Smoker))+
  geom_boxplot()
```
#(b)
```{r}
smoker=subset(girls,select=Weight,subset=Smoker=='Yes',drop=T)
nonsmoker=subset(girls,select=Weight,subset=Smoker=='No',drop=T)
X_bar=mean(nonsmoker)
Y_bar=mean(smoker)
n1=length(nonsmoker)
n2=length(smoker)
s1=sd(nonsmoker)
s2=sd(smoker)
v=round((s1^2/n1+s2^2/n2)^2/((s1^2/n1)^2/(n1-1)+(s2^2/n2)^2/(n2-1)))
percent=0.95
alpha=1-percent
q=qt(1-alpha,df=v)
bound=X_bar-Y_bar+q*sqrt(s1^2/n1+s2^2/n2)
bound
```
Comment: We are 95% confident that the true difference weight is greater than 559.3648.
#(c)
Babies born to mothers who smoke weigh less on average than babies born to non-smoking mothers.

#Bonus
#Ex. Problem 1
```{r}
likeli_binom<-function(n,p,X){
  return(log(prod(dbinom(X,n,p))))
}
n=sample(1:20,1)
p=runif(1,0,1)
N=100

X=rbinom(N,n,p)

t = seq(.01,1,by = .01) #range of lambda
y.1 <- sapply(t,function(t){likeli_binom(n,t,X)})
plot(t,y.1, xlab = 'p', ylab = 'likelihood',
type = 'l', lwd = 2)
grid(col = 4)
points(mean(X)/n, likeli_binom(n,mean(X)/n,X), lwd = 2, col = 2)
```
Comment: No matter what n,p are selected (Notice they are generated randomly), the stat of X/n is always the MLE of p.
